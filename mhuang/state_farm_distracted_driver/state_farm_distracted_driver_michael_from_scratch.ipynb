{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm Distracted Driver Detection - implemented from scratch using VGG16 weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First get standard boilerplate imports out of the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "#import os, json\n",
    "from time import time\n",
    "#from glob import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path and batch_size for desired data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path = \"data/\"\n",
    "#test_path = \"data/test/\"\n",
    "\n",
    "path = \"data/sample/\"\n",
    "test_path = \"data/sample/test/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create VGG16 model and load pre-trained weights from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess routine to center each image pixel around dataset RGB mean value, and reverse axis from RGB -> BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Input Layer for images with dimension 244 x 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.add(Lambda(vgg_preprocess, input_shape=(3,224,224)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ConvBlock(mymodel, layers, filters):\n",
    "    for i in range(layers):\n",
    "        mymodel.add(ZeroPadding2D((1,1)))\n",
    "        mymodel.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    mymodel.add(MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ConvBlock(model, 2, 64)\n",
    "ConvBlock(model, 2, 128)\n",
    "ConvBlock(model, 3, 256)\n",
    "ConvBlock(model, 3, 512)\n",
    "ConvBlock(model, 3, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FCBlock(mymodel):\n",
    "    mymodel.add(Dense(4096, activation='relu'))\n",
    "    mymodel.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "FCBlock(model)\n",
    "FCBlock(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add final output Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and load pre-trained model weights from Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'vgg16.h5'\n",
    "baseurl = 'http://www.platform.ai/models/'\n",
    "local_weights = get_file(fname, baseurl+fname, cache_subdir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(local_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune VGG16 by replacing last layer with a Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all remaining layers read-only, since we want to leverage all the pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers: layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get batch of data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(path, gen=image.ImageDataGenerator(rotation_range=10), shuffle=True, batch_size=8, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path, target_size=(224,224), color_mode='rgb', class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 images belonging to 10 classes.\n",
      "Found 250 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(path+'train', batch_size=batch_size)\n",
    "valid_batches = get_batches(path+'valid', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add new Dense layer with number of classes we are training with, and compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(train_batches.nb_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fit the model with training and validation batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "750/750 [==============================] - 27s - loss: 2.2977 - acc: 0.3400 - val_loss: 1.9581 - val_acc: 0.4200\n",
      "Epoch 2/6\n",
      "750/750 [==============================] - 25s - loss: 2.1361 - acc: 0.3893 - val_loss: 1.9078 - val_acc: 0.4160\n",
      "Epoch 3/6\n",
      "300/750 [===========>..................] - ETA: 10s - loss: 1.9370 - acc: 0.4233"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=1e-3\n",
    "model.fit_generator(train_batches, \n",
    "                    samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=6,\n",
    "                    validation_data=valid_batches,\n",
    "                    nb_val_samples=valid_batches.nb_sample\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5\n",
    "model.fit_generator(train_batches, \n",
    "                    samples_per_epoch=train_batches.nb_sample,\n",
    "                    nb_epoch=10,\n",
    "                    validation_data=valid_batches,\n",
    "                    nb_val_samples=valid_batches.nb_sample\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights('data/sample/models/try2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_batches = get_batches(test_path, shuffle=False, batch_size=2*batch_size, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Kaggle submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to play it safe, we use a sneaky trick to round down our edge predictions.\n",
    "Swap all ones with .95 and all zeros with .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare filenames by stripping path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_filenames = [filename[filename.find('/')+1:] for filename in test_batches.filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the submission data matrix the dumb way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subm1 = np.zeros(test_batches.nb_sample, dtype=[('filename', 'S128'), ('c0', float), ('c1', float), ('c2', float), ('c3', float), ('c4', float), ('c5', float), ('c6', float), ('c7', float), ('c8', float), ('c9', float)])\n",
    "\n",
    "subm1['filename'] = test_filenames\n",
    "\n",
    "subm1['c0'] = test_predictions[:,0]\n",
    "subm1['c1'] = test_predictions[:,1]\n",
    "subm1['c2'] = test_predictions[:,2]\n",
    "subm1['c3'] = test_predictions[:,3]\n",
    "subm1['c4'] = test_predictions[:,4]\n",
    "subm1['c5'] = test_predictions[:,5]\n",
    "subm1['c6'] = test_predictions[:,6]\n",
    "subm1['c7'] = test_predictions[:,7]\n",
    "subm1['c8'] = test_predictions[:,8]\n",
    "subm1['c9'] = test_predictions[:,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Kaggle submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_file_name = 'submission_' + str(int(time())) + '.csv'\n",
    "np.savetxt(submission_file_name, subm1, fmt='%s,%.5f,%.5f,%.5f,%.5f,%.5f,%.5f,%.5f,%.5f,%.5f,%.5f', header='img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the prediction by plotting a few"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to convert Category ID encoded via bit vector to Category Description from Kaggle's data description page:\n",
    "* c0: safe driving \n",
    "* c1: texting - right \n",
    "* c2: talking on the phone - right \n",
    "* c3: texting - left \n",
    "* c4: talking on the phone - left \n",
    "* c5: operating the radio \n",
    "* c6: drinking \n",
    "* c7: reaching behind \n",
    "* c8: hair and makeup \n",
    "* c9: talking to passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertCategetoryIDToTextDescription(category_id):\n",
    "    return {\n",
    "        0: 'safe driving',\n",
    "        1: 'texting - right',\n",
    "        2: 'talking on the phone - right',\n",
    "        3: 'texting - left',\n",
    "        4: 'talking on the phone - left',\n",
    "        5: 'operating the radio',\n",
    "        6: 'drinking',\n",
    "        7: 'reaching behind',\n",
    "        8: 'hair and makeup',\n",
    "        9: 'talking to passenger'\n",
    "    }.get(category_id, 'unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use argmax to find index with highest probability.\n",
    "Index happens to be same value as State Farm Cateogry Id itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred_winning_category_id = test_predictions.argmax(axis=1)\n",
    "test_pred_winning_categories = [convertCategetoryIDToTextDescription(x) for x in test_pred_winning_category_id]\n",
    "test_pred_winning_prob = np.choose(test_pred_winning_category_id, test_predictions.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to plot images for chosen indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import plots\n",
    "    \n",
    "def plots_idx(idx, path, filenames, categories, probabilities):\n",
    "    my_image_ids = np.array([int(filenames[i][filenames[i].find('_')+1:filenames[i].find('.')]) for i in idx])\n",
    "    my_categories = [categories[i] for i in idx]\n",
    "    my_probabilities = [probabilities[i] for i in idx]\n",
    "    \n",
    "    # label = <iamge id>=<probability>:<category>\n",
    "    my_labels = [\"{}={:0.2f}:{}\".format(i, j, k) for i,j,k in zip(my_image_ids, my_probabilities, my_categories)]\n",
    "    \n",
    "    plots([image.load_img(path + filenames[i]) for i in idx], titles=my_labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_view = 4\n",
    "\n",
    "idx = np.random.permutation(range(0,test_batches.nb_sample))[:n_view]\n",
    "plots_idx(idx, test_path, test_batches.filenames, test_pred_winning_categories, test_pred_winning_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
